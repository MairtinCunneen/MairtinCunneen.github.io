---
title: "Ireland's National MSc in Artificial Intelligence"
collection: teaching
type: "Postgraduate course"
permalink: /teaching/2015-spring-teaching-1
venue: "University of Limerick, Department, Accounting and Finance"
date: 2021-01-30
location: "Limerick, Ireland"
---

---
Module Description:
---

This module aims to support the MSc in Artificial Intelligence by providing a conceptual framework relating to risk, ethics, and governance, that informs AI research. Such frameworks are now standardised across international AI research programs and are no longer optional components. For such reasons, the module aims to build upon this rationale and provide a unique component informed by the established risk, ethics, and governance research group in the KBS. The purpose of the module is to frame AI technologies as technologies that need to be developed in parallel to frameworks that are informed by risk, ethics, and governance.

---
Module Outline:
---
1. (a) Define AI (b) Explore AI in different contexts (c) Interrogate the variance of AI design and the potential challenges that variation presents to AI. (d) The societal challenges to AI technologies. (e) Support the framing of AI by developing conceptual frameworks that are informed by questions of  risk, ethics and governance. (f) Learn how to engage with emerging and future AI technologies in terms of these frameworks. Accordingly, the module aims to provide students with an understanding of the concepts of risk, ethics, and governance in the context of AI and emerging AI technologies. To achieve this, it is necessary, to first provide a contextual understanding of the concept of AI and the challenges it poses to framing accurate metrics of risk, ethics and governance.

2. The contextual understanding relates to the need to develop an informed technological framework as not only an important metric to AI research itself but also as a metric intrinsic to supporting accurate anticipatory risk and governance research. The challenge of conceptually framing AI is the first knowledge output of the module.

3. The module will use examples of AI products, such as face recognition algorithms, consumer media platforms (Facebook, Spotify, Netflix, Amazon), cloud-based services (IBM Watson, personal assistant's; Siri, Alexa and Cortana) and autonomous vehicles to interrogate how risk and governance, as well as ethical metrics are dependent upon informed technological and conceptual frameworks. 

4. With an understanding of the framing challenge of AI the focus moves to consider further considerations of the ethical challenges that relate to the technologies. Particular attention is given to the question of AI autonomous decisions, risks, and related challenges to informed governance. Technological ethics is introduced to the students as an increasingly relevant aspect of AI research and technologies. This reflects an evolving change in AI research which is becoming more supportive of engaging with ethical narratives. The focus on conceptual framing and ethical challenges constitutes the second knowledge output of he module.

5. The module concludes by addressing questions of risk and governance from a number of disciplinary and cross-disciplinary perspectives relating to risk communication, ethical tensions, regulation, and legal contexts. This constitutes the culmination of the module and the third knowledge output.

---
Sample of Student Feedback
---
"Martin is very knowledgeable within the field and passionate about their specialisation."

"This module changes positively my manner of thinking"

"Excellent lecturer, made very interesting module out of what seemed like a dull subject title"

"This teacher is very great, he is challenging us, in order to be sure we get the max value from the module"

"Outstanding engagement with the students and very thought provoking"

"Martin us very inspiring with his enthusiasm and insights. He manages to interact with everyone."

(Anonymous feedback 2021)

---
Module Reading and Related texts:
---
A. M. Turing (1950) Computing Machinery and Intelligence, Mind 49: 433-460

McCarthy, J., Minsky, M., Rochester, N., & Shannon, C. E (1955) A proposal for the Dartmouth summer research project on artificial intelligence , http://www.formal.stanford.edu /jmc/history/dartmouth/dartmouth.html

Searle, J. R. (1980) Minds, brains and programs., Behavioral and Brain Sciences, 3, 417-457

Dreyfus, H. L. (1992) What computers still can't do: A critique of artificial reason , MIT Press

Calo, Ryan (2017) Artificial Intelligence Policy: A Primer and Roadmap, Available at SSRN: https://ssrn.com/abstract=3015350 or http://dx.doi.org/10.2139/ssrn.3015350

Gasser, Urs, and Virgilio A.F. Almeida (2017) A Layered Model for AI Governance, IEEE Internet Computing 21 (6) (November): 58-62. doi:10.1109/mic.2017.4180835

Johnson, D.G. & Verdicchio, M. (2017) Reframing AI Discourse, Minds & Machines 27: 575

---
My Related Research :
---
Cunneen, M., Mullins, M., & Murphy, F. (2019). Autonomous vehicles and embedded artificial intelligence: The challenges of framing machine driving decisions. Applied Artificial Intelligence, 33(8), 706-731.

Cunneen, M., Mullins, M., Murphy, F., & Gaines, S. (2019). Artificial driving intelligence and moral agency: Examining the decision ontology of unavoidable road traffic accidents through the prism of the trolley dilemma. Applied Artificial Intelligence, 33(3), 267-293.

Cunneen, M., Mullins, M., & Murphy, F. (2020). Artificial intelligence assistants and risk: framing a connectivity risk narrative. Ai & Society, 35(3), 625-634.

Lannon, C., Nelson, J., & Cunneen, M. (2021). Ethical AI for Automated Bus Lane Enforcement. Sustainability, 13(21), 11579.
